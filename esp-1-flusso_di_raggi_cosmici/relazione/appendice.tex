\appendix
\section{Varianza del rapporto di conteggi}
\label{sec:vareff}

Consideriamo%
\footnote{Questa parte è presa con pochi cambiamenti dalla nostra relazione preliminare.}
i conteggi di due coincidenze $A$ e $B$,
in cui la coincidenza $B$ contiene tutte le lastre della $A$ più un'altra diversa.
Chiamiamo $k_A$ e $k_B$ i rispettivi conteggi.
Assegnamo una distribuzione poissoniana a $k_A$ e binomiale a $k_B$ dato $k_A$:
\begin{align*}
	P(k_A;\mu)
	&= \frac{\mu^{k_A}}{k_A!}e^{-\mu} \\
	P(k_B|k_A;\epsilon)
	&= \binom{k_A}{k_B} \epsilon^{k_B} (1-\epsilon)^{k_A-k_B},
\end{align*}
ovvero $\epsilon$ è la probabilità che un raggio che fa scattare $A$
faccia scattare anche la lastra in più in $B$.
Definiamo
\begin{equation*}
	\hat\epsilon := \frac{k_B}{k_A}
\end{equation*}
e studiamone le proprietà come stimatore di $\epsilon$.
Calcoliamo la distribuzione congiunta dei conteggi:
\begin{align*}
	P(k_A,k_B;\mu,\epsilon)
	&= P(k_A;\mu) P(k_B|k_A;\epsilon) = \\
	&= \frac{e^{-\mu}}{k_B!(k_A-k_B)!} \big(\mu(1-\epsilon)\big)^{k_A} \left(\frac\epsilon{1-\epsilon}\right)^{k_B},
	\quad k_B \le k_A.
\end{align*}
Notiamo che $\hat\epsilon$ è definito per $k_A\neq 0$.
Restringiamo il dominio a $k_A\neq 0$,
quindi ricalcoliamo la normalizzazione:
\begin{align*}
	P(k_A=0,k_B=0)
	&= e^{-\mu} \implies \\
	\implies P(k_A\neq 0,k_B)
	&= \frac{P(k_A,k_B)}{1-e^{-\mu}}.
\end{align*}
Calcoliamo il valore atteso di $\hat\epsilon$:
\begin{align*}
	E[\hat\epsilon]
	&= E \left[ \frac{k_B}{k_A} \right] = \\
	&= \sum_{k_A\ge k_B} \frac{k_B}{k_A} P(k_A) P(k_B|k_A) = \\
	&= \sum_{k_A=1}^\infty \frac{P(k_A)}{k_A}
	\sum_{k_B=0}^{k_A} P(k_B|k_A) k_B = \\
	\intertext{riconosciamo che la seconda somma è la media della binomiale}
	&= \sum_{k_A=1}^\infty \frac{P(k_A)}{k_A} k_A \epsilon = \\
	&= \epsilon \sum_{k_A=1}^\infty P(k_A)
	= \epsilon,
\end{align*}
quindi $\hat\epsilon$ ha bias nullo.
Calcoliamo la varianza:
\begin{align*}
	\operatorname{Var}[\hat\epsilon]
	&= E[\hat\epsilon^2] - E[\epsilon]^2 \\
	E[\hat\epsilon^2]
	&= \sum_{k_A=1}^\infty \frac{P(k_A)}{k_A^2}
	\sum_{k_B=0}^{k_A} P(k_B|k_A) k_B^2 = \\
	\intertext{la seconda somma è $E[k_B^2|k_A]$}
	&= \sum_{k_A=1}^\infty \frac{P(k_A)}{k_A^2}
	\big (k_A\epsilon(1-\epsilon) + k_A^2\epsilon^2 \big) = \\
	&= \epsilon(1-\epsilon) \sum_{k_A=1}^\infty \frac{\mu^{k_A}}{k_Ak_A!}\frac{e^{-\mu}}{1-e^{-\mu}}
	+ \epsilon^2 \sum_{k_A=1}^\infty P(k_A) = \\
	&= \frac{\epsilon(1-\epsilon)}{e^{\mu}-1} \sum_{k_A=1}^\infty \frac{\mu^{k_A}}{k_Ak_A!} + \epsilon^2.
\end{align*}
Si può dimostrare che\footnote{L'abbiamo calcolato con WolframAlpha.}
\begin{align*}
	\sum_{k_A=1}^\infty \frac{\mu^{k_A}}{k_Ak_A!}
	&= \Ei(\mu) - \log\mu - \gamma,
\end{align*}
dove $\Ei$ è la funzione integrale esponenziale che è già implementata nelle librerie standard
e $\gamma$ è la costante di Eulero-Mascheroni $\approx 0.6$.
Quindi infine
\begin{align*}
	\operatorname{Var}[\hat\epsilon]
	&= \epsilon(1-\epsilon)\frac{\Ei(\mu) - \log\mu - \gamma}{e^\mu - 1}.
\end{align*}
Vediamo l'andamento per $\mu$ grande.
Vale $\Ei(\mu) \approx e^{\mu}/\mu$ (vedi \autoref{sec:asintmu}), dunque
\begin{align*}
	\operatorname{Var}[\hat\epsilon]
	&\approx \frac{\epsilon(1-\epsilon)}{\mu}.
\end{align*}

\subsection{Correlazione}
\label{sec:rappcorr}

Consideriamo un'ulteriore coincidenza $B'$ del tipo di $B$,
cioè con una lastra in più rispetto ad $A$.
Supponiamo che, dato un raggio che fa scattare $A$,
far scattare $B$ e far scattare $B'$ siano due eventi indipendenti.
Calcoliamo la correlazione tra $\hat\epsilon$ e $\hat\epsilon'=k_B'/k_A$.
Siano le variabili primate le corrispondenti delle variabili non primate.
\begin{align*}
	P(k_B,k_B'|k_A)
	&= P(k_B|k_A) P(k_B'|k_A) \\
	P(k_A,k_B,k_B')
	&= P(k_B,k_B'|k_A) P(k_A) = \\
	&= P(k_A) P(k_B|k_A) P(k_B'|k_A) \\
	E[\hat\epsilon \hat\epsilon']
	&= \sum_{k_Bk_B'k_A} P(k_A) P(k_B|k_A) P(k_B'|k_A) \frac{k_Bk_B'}{k_A^2} = \\
	&= \sum_{k_A} \frac{P(k_A)}{k_A^2} E[k_B|k_A] E[k_B'|k_A] = \\
	&= \sum_{k_A} \frac{P(k_A)}{k_A^2} k_A\epsilon\,k_A\epsilon' = \\
	&= \epsilon\epsilon' \\
	\operatorname{Cov}[\hat\epsilon,\hat\epsilon']
	&= E[\hat\epsilon\hat\epsilon'] - E[\hat\epsilon]E[\hat\epsilon'] = 0.
\end{align*}

\subsection{Sviluppo asintotico in $\mu$}
\label{sec:asintmu}

Dimostriamo lo sviluppo asintotico della funzione $\Ei$ usato precedentemente
e calcoliamo anche i termini superiori al primo.
L'integrale esponenziale è definito come
\begin{equation*}
	\operatorname{Ei}(x)
	= -\fint_{-x}^\infty \de t \frac{e^t}t
	= \fint_{-\infty}^x \de t \frac{e^t}t,
\end{equation*}
quindi le derivate sono
\begin{align*}
	\Ei'(x) &= \frac{e^x}x, \\
	\Ei''(x) &= \frac{xe^x - e^x}x^2 = e^x \big(x^{-1} + O(x^{-2})\big).
\end{align*}
Poiché all'ordine $x^{-1}$ $\Ei'=\Ei''$, vale anche $\Ei=\Ei'$:
\begin{equation*}
	\Ei(x) = e^x \big(x^{-1} + O(x^{-2}) \big).
\end{equation*}
Calcoliamo $\Ei(x)e^{-x}$ passando attraverso l'integrale:
\begin{align*}
	\int\de x\, \Ei(x) e^{-x}
	&= \Ei(x)(-e^{-x}) + \int\de x\, \Ei'(x)e^{-x} = \\
	&= -\Ei(x)e^{-x}  + \int\frac{\de x}x = \\
	&= -\Ei(x)e^{-x} + \log x + C, \\
	\Ei(x)e^{-x}
	&= \dv{}{x} \int\de x\, \Ei(x)e^{-x} = \\
	&= \dv{}{x} \left( -\frac1x + O\left(\frac1{x^2}\right) + \log x + C \right) = \\
	&= \frac1x + \frac1{x^2} + O\left(\frac1{x^3}\right).
\end{align*}
Per induzione a vista si ottiene:
\begin{align*}
	\frac{\Ei(x)}x
	&= \sum_{k=0}^N \frac{\de^k}{\de x^k} \frac{(-1)^k}{x} + O\left(\frac1{x^{N+2}}\right) = \\
	&= \sum_{k=0}^N \frac{k!}{x^{1+k}} + O\left(\frac1{x^{N+2}}\right).
\end{align*}
La somma non converge per $N\to\infty$,
è uno sviluppo che per ogni $N$ finito è utile per $x$ abbastanza grande.
In particolare al secondo ordine
\begin{equation*}
	\frac{\Ei(x)}{e^x} = \frac1x + \frac1{x^2}.
\end{equation*}
